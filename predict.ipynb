{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import plot, show, savefig, xlim, figure, ylim, legend, boxplot, setp, axes\n",
    "from OCT import OCTClassifier\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from decision_tree_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If one of us apologizes when our discussion deteriorates, the discussion ends.\n",
    "2. I know we can ignore our differences, even if things get hard sometimes.\n",
    "3. When we need it, we can take our discussions with my spouse from the beginning and correct it.\n",
    "4. When I discuss with my spouse, to contact him will eventually work.\n",
    "5. The time I spent with my wife is special for us.\n",
    "6. We don't have time at home as partners.\n",
    "7. We are like two strangers who share the same environment at home rather than family.\n",
    "8. I enjoy our holidays with my wife.\n",
    "9. I enjoy traveling with my wife.\n",
    "10. Most of our goals are common to my spouse.\n",
    "11. I think that one day in the future, when I look back, I see that my spouse and I have been in harmony with each other.\n",
    "12. My spouse and I have similar values in terms of personal freedom.\n",
    "13. My spouse and I have similar sense of entertainment.\n",
    "14. Most of our goals for people (children, friends, etc.) are the same.\n",
    "15. Our dreams with my spouse are similar and harmonious.\n",
    "16. We're compatible with my spouse about what love should be.\n",
    "17. We share the same views about being happy in our life with my spouse\n",
    "18. My spouse and I have similar ideas about how marriage should be\n",
    "19. My spouse and I have similar ideas about how roles should be in marriage\n",
    "20. My spouse and I have similar values in trust.\n",
    "21. I know exactly what my wife likes.\n",
    "22. I know how my spouse wants to be taken care of when she/he sick.\n",
    "23. I know my spouse's favorite food.\n",
    "24. I can tell you what kind of stress my spouse is facing in her/his life.\n",
    "25. I have knowledge of my spouse's inner world.\n",
    "26. I know my spouse's basic anxieties.\n",
    "27. I know what my spouse's current sources of stress are.\n",
    "28. I know my spouse's hopes and wishes.\n",
    "29. I know my spouse very well.\n",
    "30. I know my spouse's friends and their social relationships.\n",
    "31. I feel aggressive when I argue with my spouse.\n",
    "32. When discussing with my spouse, I usually use expressions such as ‘you always’ or ‘you never’ .\n",
    "33. I can use negative statements about my spouse's personality during our discussions.\n",
    "34. I can use offensive expressions during our discussions.\n",
    "35. I can insult my spouse during our discussions.\n",
    "36. I can be humiliating when we discussions.\n",
    "37. My discussion with my spouse is not calm.\n",
    "38. I hate my spouse's way of open a subject.\n",
    "39. Our discussions often occur suddenly.\n",
    "40. We're just starting a discussion before I know what's going on.\n",
    "41. When I talk to my spouse about something, my calm suddenly breaks.\n",
    "42. When I argue with my spouse, ı only go out and I don't say a word.\n",
    "43. I mostly stay silent to calm the environment a little bit.\n",
    "44. Sometimes I think it's good for me to leave home for a while.\n",
    "45. I'd rather stay silent than discuss with my spouse.\n",
    "46. Even if I'm right in the discussion, I stay silent to hurt my spouse.\n",
    "47. When I discuss with my spouse, I stay silent because I am afraid of not being able to control my anger.\n",
    "48. I feel right in our discussions.\n",
    "49. I have nothing to do with what I've been accused of.\n",
    "50. I'm not actually the one who's guilty about what I'm accused of.\n",
    "51. I'm not the one who's wrong about problems at home.\n",
    "52. I wouldn't hesitate to tell my spouse about her/his inadequacy.\n",
    "53. When I discuss, I remind my spouse of her/his inadequacy.\n",
    "54. I'm not afraid to tell my spouse about her/his incompetence.\n",
    "\n",
    "Notes:\n",
    "- Class label indicates divorce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('divorce/divorce.csv', delimiter=';')\n",
    "y = df.Class\n",
    "X = df.drop(columns='Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.35416717522843966\n",
      "            Iterations: 62\n",
      "            Function evaluations: 65\n",
      "            Gradient evaluations: 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Class</td>      <th>  No. Observations:  </th>  <td>   127</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   118</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     8</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 06 Dec 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.7718</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:34:21</td>     <th>  Log-Likelihood:    </th> <td> -20.090</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -88.026</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.711e-25</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr1</th>  <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr2</th>  <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr3</th>  <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr4</th>  <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr5</th>  <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr6</th>  <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr7</th>  <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr8</th>  <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr9</th>  <td>    0.2237</td> <td>    0.668</td> <td>    0.335</td> <td> 0.738</td> <td>   -1.085</td> <td>    1.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr10</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr11</th> <td>    0.3142</td> <td>    0.616</td> <td>    0.510</td> <td> 0.610</td> <td>   -0.892</td> <td>    1.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr12</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr13</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr14</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr15</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr16</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr17</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr18</th> <td>    0.2316</td> <td>    0.693</td> <td>    0.334</td> <td> 0.738</td> <td>   -1.127</td> <td>    1.590</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr19</th> <td>    0.1635</td> <td>    0.729</td> <td>    0.224</td> <td> 0.822</td> <td>   -1.265</td> <td>    1.592</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr20</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr21</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr22</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr23</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr24</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr25</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr26</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr27</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr28</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr29</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr30</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr31</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr32</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr33</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr34</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr35</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr36</th> <td>    0.3053</td> <td>    0.468</td> <td>    0.653</td> <td> 0.514</td> <td>   -0.611</td> <td>    1.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr37</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr38</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr39</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr40</th> <td>    0.4589</td> <td>    0.426</td> <td>    1.077</td> <td> 0.281</td> <td>   -0.376</td> <td>    1.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr41</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr42</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr43</th> <td>   -0.2185</td> <td>    0.233</td> <td>   -0.939</td> <td> 0.348</td> <td>   -0.674</td> <td>    0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr44</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr45</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr46</th> <td>   -0.1732</td> <td>    0.214</td> <td>   -0.809</td> <td> 0.418</td> <td>   -0.593</td> <td>    0.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr47</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr48</th> <td>   -0.4000</td> <td>    0.216</td> <td>   -1.851</td> <td> 0.064</td> <td>   -0.824</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr49</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr50</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr51</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr52</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr53</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr54</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  Class   No. Observations:                  127\n",
       "Model:                          Logit   Df Residuals:                      118\n",
       "Method:                           MLE   Df Model:                            8\n",
       "Date:                Sun, 06 Dec 2020   Pseudo R-squ.:                  0.7718\n",
       "Time:                        19:34:21   Log-Likelihood:                -20.090\n",
       "converged:                       True   LL-Null:                       -88.026\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.711e-25\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const               0        nan        nan        nan         nan         nan\n",
       "Atr1                0        nan        nan        nan         nan         nan\n",
       "Atr2                0        nan        nan        nan         nan         nan\n",
       "Atr3                0        nan        nan        nan         nan         nan\n",
       "Atr4                0        nan        nan        nan         nan         nan\n",
       "Atr5                0        nan        nan        nan         nan         nan\n",
       "Atr6                0        nan        nan        nan         nan         nan\n",
       "Atr7                0        nan        nan        nan         nan         nan\n",
       "Atr8                0        nan        nan        nan         nan         nan\n",
       "Atr9           0.2237      0.668      0.335      0.738      -1.085       1.532\n",
       "Atr10               0        nan        nan        nan         nan         nan\n",
       "Atr11          0.3142      0.616      0.510      0.610      -0.892       1.521\n",
       "Atr12               0        nan        nan        nan         nan         nan\n",
       "Atr13               0        nan        nan        nan         nan         nan\n",
       "Atr14               0        nan        nan        nan         nan         nan\n",
       "Atr15               0        nan        nan        nan         nan         nan\n",
       "Atr16               0        nan        nan        nan         nan         nan\n",
       "Atr17               0        nan        nan        nan         nan         nan\n",
       "Atr18          0.2316      0.693      0.334      0.738      -1.127       1.590\n",
       "Atr19          0.1635      0.729      0.224      0.822      -1.265       1.592\n",
       "Atr20               0        nan        nan        nan         nan         nan\n",
       "Atr21               0        nan        nan        nan         nan         nan\n",
       "Atr22               0        nan        nan        nan         nan         nan\n",
       "Atr23               0        nan        nan        nan         nan         nan\n",
       "Atr24               0        nan        nan        nan         nan         nan\n",
       "Atr25               0        nan        nan        nan         nan         nan\n",
       "Atr26               0        nan        nan        nan         nan         nan\n",
       "Atr27               0        nan        nan        nan         nan         nan\n",
       "Atr28               0        nan        nan        nan         nan         nan\n",
       "Atr29               0        nan        nan        nan         nan         nan\n",
       "Atr30               0        nan        nan        nan         nan         nan\n",
       "Atr31               0        nan        nan        nan         nan         nan\n",
       "Atr32               0        nan        nan        nan         nan         nan\n",
       "Atr33               0        nan        nan        nan         nan         nan\n",
       "Atr34               0        nan        nan        nan         nan         nan\n",
       "Atr35               0        nan        nan        nan         nan         nan\n",
       "Atr36          0.3053      0.468      0.653      0.514      -0.611       1.222\n",
       "Atr37               0        nan        nan        nan         nan         nan\n",
       "Atr38               0        nan        nan        nan         nan         nan\n",
       "Atr39               0        nan        nan        nan         nan         nan\n",
       "Atr40          0.4589      0.426      1.077      0.281      -0.376       1.294\n",
       "Atr41               0        nan        nan        nan         nan         nan\n",
       "Atr42               0        nan        nan        nan         nan         nan\n",
       "Atr43         -0.2185      0.233     -0.939      0.348      -0.674       0.237\n",
       "Atr44               0        nan        nan        nan         nan         nan\n",
       "Atr45               0        nan        nan        nan         nan         nan\n",
       "Atr46         -0.1732      0.214     -0.809      0.418      -0.593       0.246\n",
       "Atr47               0        nan        nan        nan         nan         nan\n",
       "Atr48         -0.4000      0.216     -1.851      0.064      -0.824       0.024\n",
       "Atr49               0        nan        nan        nan         nan         nan\n",
       "Atr50               0        nan        nan        nan         nan         nan\n",
       "Atr51               0        nan        nan        nan         nan         nan\n",
       "Atr52               0        nan        nan        nan         nan         nan\n",
       "Atr53               0        nan        nan        nan         nan         nan\n",
       "Atr54               0        nan        nan        nan         nan         nan\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# akhilesh: use statmodel to fit\n",
    "import statsmodels.api as sm\n",
    "model = sm.Logit(y_train, sm.add_constant(X_train)) #Define the model; sm.add_constant(X) adds an intercept term to the model\n",
    "# result = model.fit(maxiter=100,method='ncg') #Fit the model\n",
    "result = model.fit_regularized(maxiter=100,method='l1',alpha=10) #Fit the model\n",
    "result.summary() #Print summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9848484848484849\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(result.params,sm.add_constant(X_test)) \n",
    "# calculate accuracy scores\n",
    "roc_auc= roc_auc_score(y_test, y_predict)\n",
    "print(\"AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.38990540939626417\n",
      "            Iterations: 22\n",
      "            Function evaluations: 23\n",
      "            Gradient evaluations: 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Class</td>      <th>  No. Observations:  </th>  <td>   127</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   124</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 06 Dec 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.7319</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:39:54</td>     <th>  Log-Likelihood:    </th> <td> -23.599</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -88.026</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.047e-28</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -1.3061</td> <td>    0.303</td> <td>   -4.307</td> <td> 0.000</td> <td>   -1.900</td> <td>   -0.712</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr10</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr12</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr19</th> <td>    0.7840</td> <td>    0.435</td> <td>    1.804</td> <td> 0.071</td> <td>   -0.068</td> <td>    1.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr20</th> <td>    0.5018</td> <td>    0.473</td> <td>    1.061</td> <td> 0.289</td> <td>   -0.425</td> <td>    1.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Atr41</th> <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  Class   No. Observations:                  127\n",
       "Model:                          Logit   Df Residuals:                      124\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Sun, 06 Dec 2020   Pseudo R-squ.:                  0.7319\n",
       "Time:                        19:39:54   Log-Likelihood:                -23.599\n",
       "converged:                       True   LL-Null:                       -88.026\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.047e-28\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -1.3061      0.303     -4.307      0.000      -1.900      -0.712\n",
       "Atr10               0        nan        nan        nan         nan         nan\n",
       "Atr12               0        nan        nan        nan         nan         nan\n",
       "Atr19          0.7840      0.435      1.804      0.071      -0.068       1.636\n",
       "Atr20          0.5018      0.473      1.061      0.289      -0.425       1.429\n",
       "Atr41               0        nan        nan        nan         nan         nan\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use top 8 features\n",
    "# Atr9, 11,15,17,18,19,20,40: 8,10,14,16,17,18,19,39\n",
    "X_train_trimmed = X_train.iloc[:,[9,11,18,19,40]]\n",
    "X_test_trimmed = X_test.iloc[:,[9,11,18,19,40]]\n",
    "\n",
    "model = sm.Logit(y_train, sm.add_constant(X_train_trimmed)) #Define the model; sm.add_constant(X) adds an intercept term to the model\n",
    "# result = model.fit(maxiter=100,method='ncg') #Fit the model\n",
    "result = model.fit_regularized(maxiter=100,method='l1',alpha=10) #Fit the model\n",
    "result.summary() #Print summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statmodel LR auc score: 0.9902597402597402\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(result.params,sm.add_constant(X_test_trimmed)) \n",
    "# calculate accuracy scores\n",
    "roc_auc= roc_auc_score(y_test, y_predict)\n",
    "print(\"Statmodel LR auc score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(11, 0.11774621922809603), (18, 0.1764996498705012), (19, 0.1256911480043183), (35, 0.003604884118433394), (36, 0.22713171727885817), (40, 0.24430005855800382), (43, -0.04758116829687479), (46, -0.09073355408280952), (48, -0.14889159600567967)]\n"
     ]
    }
   ],
   "source": [
    "# zach LR Define L1 model\n",
    "l1_model = LogisticRegressionCV(Cs=10, cv=10, penalty='l1', scoring='roc_auc',\n",
    "                                solver='liblinear', max_iter=100, random_state=0)\n",
    "l1_model.fit(X_train,y_train)\n",
    "# print(\"l1 coeffs\",l1_model.coef_)\n",
    "# get non zero features\n",
    "num_feature = 1\n",
    "non_zeros_coeffs = []\n",
    "for i in range(1,l1_model.coef_.shape[1]+1):\n",
    "    if l1_model.coef_[0,i-1]!=0:\n",
    "        non_zeros_coeffs.append(tuple((i,l1_model.coef_[0,i-1])))\n",
    "print(non_zeros_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(11, 0.11774621922809603), (18, 0.1764996498705012), (19, 0.1256911480043183), (35, 0.003604884118433394), (36, 0.22713171727885817), (40, 0.24430005855800382), (43, -0.04758116829687479), (46, -0.09073355408280952), (48, -0.14889159600567967)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(cv=10, max_iter=1000, random_state=0, scoring='roc_auc')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define L2 model\n",
    "l2_model = LogisticRegressionCV(Cs=10, cv=10, penalty='l2', scoring='roc_auc',\n",
    "                                solver='lbfgs', max_iter=1000, random_state=0)\n",
    "l2_model.fit(X_train,y_train)\n",
    "# print(\"l2 coeffs\",l2_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9913419913419913, 1.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_model.score(X_test,y_test), l2_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CART grid search + in/out-of-sample accuracy\n",
    "estimator = DecisionTreeClassifier(random_state=0)\n",
    "param_grid = {'max_depth':[1, 2, 3, 4, 5], 'ccp_alpha':[0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "search = GridSearchCV(estimator=estimator,\n",
    "                      param_grid=param_grid,\n",
    "                      cv=3)\n",
    "search.fit(X_train,y_train)\n",
    "decision_tree = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of DecisionTreeClassifier(ccp_alpha=0, max_depth=1, random_state=0)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample accuracy: 99.21259842519686%\n",
      "Out-of-sample accuracy: 95.34883720930233%\n"
     ]
    }
   ],
   "source": [
    "# Train using CART\n",
    "cart_insample = decision_tree.score(X_train,y_train)\n",
    "cart_outofsample = decision_tree.score(X_test,y_test)\n",
    "print(\"In-sample accuracy: {}%\".format(100*cart_insample))\n",
    "print(\"Out-of-sample accuracy: {}%\".format(100*cart_outofsample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaling to X_train and X_test (OCT requires scaling features to [0,1])\n",
    "scaler = MinMaxScaler()\n",
    "index = X_train.index\n",
    "columns = X_train.columns\n",
    "data = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(data=data, index=index, columns=columns)\n",
    "index = X_test.index\n",
    "data = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(data=data, index=index, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter LogToConsole unchanged\n",
      "   Value: 1  Min: 0  Max: 1  Default: 1\n",
      "Changed value of parameter MIPGap to 0.01\n",
      "   Prev: 0.0001  Min: 0.0  Max: inf  Default: 0.0001\n",
      "Changed value of parameter TimeLimit to 60.0\n",
      "   Prev: inf  Min: 0.0  Max: inf  Default: inf\n",
      "Gurobi Optimizer version 9.0.1 build v9.0.1rc0 (linux64)\n",
      "Optimize a model with 3251 rows, 1456 columns and 115163 nonzeros\n",
      "Model fingerprint: 0x1c937fcb\n",
      "Variable types: 39 continuous, 1417 integer (1417 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-01, 1e+02]\n",
      "  Objective range  [1e-01, 9e-01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+02]\n",
      "Presolve added 38 rows and 38 columns\n",
      "Presolve time: 0.17s\n",
      "Presolved: 3289 rows, 1494 columns, 89236 nonzeros\n",
      "Variable types: 28 continuous, 1466 integer (1416 binary)\n",
      "Found heuristic solution: objective 61.8000000\n",
      "\n",
      "Root relaxation: objective 1.142000e+02, 471 iterations, 0.02 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0  114.20000    0  153   61.80000  114.20000  84.8%     -    0s\n",
      "H    0     0                      61.9000000  114.20000  84.5%     -    0s\n",
      "     0     0  114.20000    0  188   61.90000  114.20000  84.5%     -    0s\n",
      "     0     0  114.20000    0  194   61.90000  114.20000  84.5%     -    0s\n",
      "H    0     0                      67.3000000  114.20000  69.7%     -    0s\n",
      "     0     0  114.20000    0  174   67.30000  114.20000  69.7%     -    0s\n",
      "     0     0  114.20000    0  183   67.30000  114.20000  69.7%     -    0s\n",
      "     0     0  114.20000    0   68   67.30000  114.20000  69.7%     -    1s\n",
      "     0     0  114.20000    0   67   67.30000  114.20000  69.7%     -    1s\n",
      "H    0     0                      71.8000000  114.20000  59.1%     -    1s\n",
      "     0     0  114.20000    0   39   71.80000  114.20000  59.1%     -    1s\n",
      "     0     0  114.20000    0   37   71.80000  114.20000  59.1%     -    1s\n",
      "H    0     0                      80.8000000  114.20000  41.3%     -    1s\n",
      "     0     0  114.20000    0   20   80.80000  114.20000  41.3%     -    1s\n",
      "     0     0  114.20000    0   27   80.80000  114.20000  41.3%     -    1s\n",
      "H    0     0                      91.6000000  114.20000  24.7%     -    1s\n",
      "H    0     0                      97.9000000  114.20000  16.6%     -    1s\n",
      "     0     0  114.20000    0   25   97.90000  114.20000  16.6%     -    1s\n",
      "     0     0  114.20000    0   25   97.90000  114.20000  16.6%     -    2s\n",
      "H    0     2                     100.6000000  114.20000  13.5%     -    2s\n",
      "     0     2  114.20000    0   25  100.60000  114.20000  13.5%     -    2s\n",
      "H   31    38                     112.4000000  114.20000  1.60%  34.4    2s\n",
      "H   69    71                     113.3000000  114.20000  0.79%  28.1    2s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 7\n",
      "  Cover: 301\n",
      "  Clique: 1\n",
      "  MIR: 58\n",
      "  StrongCG: 1\n",
      "  Flow cover: 33\n",
      "  GUB cover: 18\n",
      "\n",
      "Explored 72 nodes (7650 simplex iterations) in 2.44 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 10: 113.3 112.4 100.6 ... 61.8\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 1.133000000000e+02, best bound 1.142000000000e+02, gap 0.7944%\n",
      "Training time: 2.8141632080078125 sec\n",
      "In-sample accuracy: 99.21259842519686%\n",
      "Out-of-sample accuracy: 95.34883720930233%\n"
     ]
    }
   ],
   "source": [
    "# Train using OCT\n",
    "start_time = time.time()\n",
    "oct_tree = OCTClassifier(max_depth=3,\n",
    "                         lambda_=0.1,\n",
    "                         gurobi_TimeLimit=60,\n",
    "                         gurobi_LogToConsole=1)\n",
    "oct_tree.fit(X_train,y_train)\n",
    "end_time = time.time()\n",
    "oct_traintime = end_time - start_time\n",
    "oct_insample = oct_tree.score(X_train,y_train)\n",
    "oct_outofsample = oct_tree.score(X_test,y_test)\n",
    "print(\"Training time: {} sec\".format(oct_traintime))\n",
    "print(\"In-sample accuracy: {}%\".format(\n",
    "    100*oct_insample))\n",
    "print(\"Out-of-sample accuracy: {}%\".format(\n",
    "    100*oct_outofsample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_tree(decision_tree=oct_tree, feature_names=columns, name=\"Tree\", write_dot=False, write_png=True)\n",
    "Image(filename = 'Tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divorced 275x more likely to reply affirmatively to Atr7\n",
    "married_data=data[data['Class']==0].drop(columns=['Class'])\n",
    "divorced_data=data[data['Class']==1].drop(columns=['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of our custom ensemble on test data is 0.998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# SVC\n",
    "svc = SVC(C=0.1,kernel = 'linear', random_state = 0,probability=True)\n",
    "svc.fit(X_train, y_train)\n",
    "y_predSVC = svc.predict_proba(X_test).T[1]\n",
    "SVC_score = roc_auc_score(y_test,y_predSVC)   \n",
    "\n",
    "print('AUC of our custom ensemble on test data is {}'.format(round(SVC_score, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of our custom ensemble on test data is 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# SVC\n",
    "svc = SVC(C=0.1,kernel = 'rbf', random_state = 0,probability=True)\n",
    "svc.fit(X_train, y_train)\n",
    "y_predSVC = svc.predict_proba(X_test).T[1]\n",
    "SVC_score = roc_auc_score(y_test,y_predSVC)   \n",
    "\n",
    "print('AUC of our custom ensemble on test data is {}'.format(round(SVC_score, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
